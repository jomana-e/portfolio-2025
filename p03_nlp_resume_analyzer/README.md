\# ğŸ§  NLP Resume \& Job Description Analyzer



\*\*Project 3 â€” AI Portfolio\*\*

An intelligent, end-to-end NLP web app that analyzes resumes against job descriptions using semantic similarity, keyword extraction, and skill taxonomy coverage.



---



\## ğŸš€ Overview



This project leverages \*\*transformer-based embeddings\*\* and \*\*keyword extraction models\*\* to evaluate how well a candidateâ€™s resume aligns with a job description.



It performs:

\- \*\*Semantic similarity scoring\*\* between resume and JD text

\- \*\*KeyBERT-based keyword extraction\*\* for important job terms

\- \*\*Dynamic filtering\*\* to remove irrelevant words (verbs, companies, cities, etc.)

\- \*\*Taxonomy-based skill coverage\*\* analysis from a YAML skill hierarchy

\- \*\*Actionable resume improvement suggestions\*\* generated automatically



The web interface, built in \*\*Streamlit\*\*, provides a one-click workflow to analyze resumes and export a professional \*\*PDF report\*\* summarizing alignment, missing skills, and improvement areas.



---



\## ğŸ§© Tech Stack



| Layer | Technology |

|-------|-------------|

| \*\*NLP \& ML\*\* | Sentence Transformers (`all-MiniLM-L6-v2`), KeyBERT, spaCy, RapidFuzz |

| \*\*App UI\*\* | Streamlit |

| \*\*Visualization\*\* | Plotly (Radar Chart), ReportLab (PDF export) |

| \*\*Data Storage\*\* | YAML-based Skill Taxonomy |

| \*\*Automation\*\* | Pre-commit hooks, Ruff, Verified Streamlit Deployment |

| \*\*Environment\*\* | Conda / Python virtualenv |



---



\## ğŸ“‚ Project Structure



```bash

p03\_nlp\_resume\_analyzer/

â”‚

â”œâ”€â”€ app/

â”‚ â””â”€â”€ Main.py # Streamlit web interface

â”‚

â”œâ”€â”€ scripts/

â”‚ â””â”€â”€ nlp\_core.py # Core NLP logic (embeddings, filters, taxonomy)

â”‚

â”œâ”€â”€ data/

â”‚ â”œâ”€â”€ skills.yaml # Hierarchical taxonomy of AI/ML skills

â”‚ â””â”€â”€ irrelevant\_terms\_cache.json # Dynamic term cache

â”‚

â”œâ”€â”€ tmp\_uploads/ # Temporary resume uploads (runtime)

â”‚

â”œâ”€â”€ requirements.txt # Environment dependencies

â”œâ”€â”€ Makefile # Lint/test/run shortcuts

â””â”€â”€ README.md # Project documentation

```





---



\## ğŸ§  Model \& NLP Summary



\- \*\*Embedding Model:\*\* `all-MiniLM-L6-v2` (sentence-transformers)

\- \*\*Keyword Extractor:\*\* `KeyBERT`

\- \*\*Similarity Metric:\*\* Cosine similarity

\- \*\*Skill Taxonomy:\*\* Custom YAML taxonomy (AI, ML, Data, Cloud, etc.)

\- \*\*Filtering Pipeline:\*\*

&nbsp; - Removes verbs (e.g., \*developing, leading\*) but keeps nouns (\*development, leadership\*)

&nbsp; - Excludes company \& city names (case-insensitive)

&nbsp; - Always capitalizes â€œMLâ€ correctly

&nbsp; - Dynamic self-updating cache via `irrelevant\_terms\_cache.json`



---



\## ğŸ“ˆ Core Features



\- ğŸ“„ \*\*PDF Resume Parsing:\*\* Reads `.pdf`, `.docx`, or text input automatically

\- ğŸ§  \*\*Semantic Analysis:\*\* Measures deep alignment between resume and JD text

\- ğŸ” \*\*Keyword Insight:\*\* Highlights missing and overlapping key concepts

\- ğŸ“Š \*\*Skill Taxonomy Coverage:\*\* Radar chart visualization of domain-level alignment

\- âœï¸ \*\*Targeted Recommendations:\*\* Contextual bullet suggestions to improve the resume

\- ğŸ’¾ \*\*Report Export:\*\* One-click downloadable professional report (PDF format)



---



\## ğŸ§° How to Run Locally



\### 1ï¸âƒ£ Setup Environment



```bash

conda create -n portfolio-py python=3.10

conda activate portfolio-py

pip install -r requirements.txt

```



\### 2ï¸âƒ£ Launch the Streamlit App



```bash

streamlit run app/Main.py

```

Then open your browser at:

ğŸ‘‰ \[http://localhost:8501](http://localhost:8501)



---



\## ğŸ§© Example Workflow



1. Upload or paste your resume.

2\. Paste a job description.

3\. Click ğŸ” Analyze to view:

&nbsp;	- Top job keywords

&nbsp;	- Semantic gaps

&nbsp;	- Skill coverage radar chart

4\. Click ğŸ“„ Generate PDF Report for a full summary.



---



\## ğŸ¯ Key Highlights



* Dynamic NLP filters automatically adapt to job context
* Hybrid approach: rule-based + transformer-based matching
* YAML-driven taxonomy ensures explainability and extensibility
* Fully deployable Streamlit app (tested on Streamlit Cloud)
* Strict code quality enforced by Ruff and pre-commit



---



\## ğŸ’¡ Lessons \& Takeaways



* Combining semantic similarity with taxonomy-based coverage improves resumeâ€“JD matching accuracy
* Real-world NLP apps benefit from dynamic filtering and caching for cleaner results
* Structuring ML/NLP apps modularly (UI vs. logic layers) simplifies deployment and maintenance
* Integrating visualization and report export turns raw NLP analysis into user-facing insights



---



\## ğŸŒ Live Demo



ğŸ§  NLP Resume Analyzer App:

\[https://ja-portfolio-nlp-resume-analyzer.streamlit.app](https://ja-portfolio-nlp-resume-analyzer.streamlit.app)
